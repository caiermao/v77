---
title: A Word Embeddings Informed Focused Topic Model
abstract: In natural language processing and related fields, it has been shown that
  the word embeddings can successfully capture both the semantic and syntactic features
  of words. They can serve as complementary information to topics models, especially
  for the cases where word co-occurrence data is insufficient, such as with short
  texts. In this paper, we propose a focused topic model where how a topic focuses
  on words is informed by word embeddings. Our models is able to discover more informed
  and focused topics with more representative words, leading to better modelling accuracy
  and topic quality. With the data argumentation technique, we can derive an efficient
  Gibbs sampling algorithm that benefits from the fully local conjugacy of the model.
  We conduct extensive experiments on several real world datasets, which demonstrate
  that our model achieves comparable or improved performance in terms of both perplexity
  and topic coherence, particularly in handling short text data.
section: Accepted Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: zhao17a
month: 0
tex_title: A Word Embeddings Informed Focused Topic Model
firstpage: 423
lastpage: 438
page: 423-438
order: 423
cycles: false
author:
- given: He
  family: Zhao
- given: Lan
  family: Du
- given: Wray
  family: Buntine
date: 2017-11-11
address: 
publisher: PMLR
container-title: Proceedings of the Ninth Asian Conference on Machine Learning
volume: '77'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 11
  - 11
pdf: http://proceedings.mlr.press/v77/zhao17a/zhao17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
