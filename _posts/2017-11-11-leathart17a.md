---
title: Probability Calibration Trees
abstract: Obtaining accurate and well calibrated probability estimates from classifiers
  is useful in many applications, for example, when minimising the expected cost of
  classifications. Existing methods of calibrating probability estimates are applied
  globally, ignoring the potential for improvements by applying a more fine-grained
  model. We propose probability calibration trees, a modification of logistic model
  trees that identifies regions of the input space in which different probability
  calibration models are learned to improve performance. We compare probability calibration
  trees to two widely used calibration methods—isotonic regression and Platt scaling—and
  show that our method results in lower root mean squared error on average than both
  methods, for estimates produced by a variety of base learners.
section: Accepted Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: leathart17a
month: 0
tex_title: Probability Calibration Trees
firstpage: 145
lastpage: 160
page: 145-160
order: 145
cycles: false
author:
- given: Tim
  family: Leathart
- given: Eibe
  family: Frank
- given: Geoffrey
  family: Holmes
- given: Bernhard
  family: Pfahringer
date: 2017-11-11
address: 
publisher: PMLR
container-title: Proceedings of the Ninth Asian Conference on Machine Learning
volume: '77'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 11
  - 11
pdf: http://proceedings.mlr.press/v77/leathart17a/leathart17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
