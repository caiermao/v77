---
title: Deep Competitive Pathway Networks
abstract: 'In the design of deep neural architectures, recent studies have demonstrated
  the benefits of grouping subnetworks into a larger network. For examples, the Inception
  architecture integrates multi-scale subnetworks and the residual network can be
  regarded that a residual unit combines a residual subnetwork with an identity shortcut.
  In this work, we embrace this observation and propose the Competitive Pathway Network
  (CoPaNet). The CoPaNet comprises a stack of competitive pathway units and each unit
  contains multiple parallel residual-type subnetworks followed by a max operation
  for feature competition. This mechanism enhances the model capability by learning
  a variety of features in subnetworks. The proposed strategy explicitly shows that
  the features propagate through pathways in various routing patterns, which is referred
  to as pathway encoding of category information. Moreover, the cross-block shortcut
  can be added to the CoPaNet to encourage feature reuse. We evaluated the proposed
  CoPaNet on four object recognition benchmarks: CIFAR-10, CIFAR-100, SVHN, and ImageNet.
  CoPaNet obtained the state-of-the-art or comparable results using similar amounts
  of parameters. The code of CoPaNet is available at: \urlhttps://github.com/JiaRenChang/CoPaNet.'
section: Accepted Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: chang17a
month: 0
tex_title: Deep Competitive Pathway Networks
firstpage: 264
lastpage: 278
page: 264-278
order: 264
cycles: false
author:
- given: Jia-Ren
  family: Chang
- given: Yong-Sheng
  family: Chen
date: 2017-11-11
address: 
publisher: PMLR
container-title: Proceedings of the Ninth Asian Conference on Machine Learning
volume: '77'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 11
  - 11
pdf: http://proceedings.mlr.press/v77/chang17a/chang17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
