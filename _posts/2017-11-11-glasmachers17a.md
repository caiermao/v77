---
title: Limits of End-to-End Learning
abstract: "End-to-end learning refers to training a possibly complex learning system
  by applying gradient-based learning to the system as a whole. End-to-end learning
  systems are specifically designed so that all modules are differentiable. In effect,
  not only a central learning machine, but also all “peripheral” modules like representation
  learning and memory formation are covered by a holistic learning process. The power
  of end-to-end learning has been demonstrated on many tasks, like playing a whole
  array of Atari video games with a single architecture. While pushing for solutions
  to more challenging tasks, network architectures keep growing more and more complex.\r
  In this paper we ask the question whether and to what extent end-to-end learning
  is a future-proof technique in the sense of \\emphscaling to complex and diverse
  data processing architectures. We point out potential inefficiencies, and we argue
  in particular that end-to-end learning does not make optimal use of the modular
  design of present neural networks. Our surprisingly simple experiments demonstrate
  these inefficiencies, up to the complete breakdown of learning."
section: Accepted Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: glasmachers17a
month: 0
tex_title: Limits of End-to-End Learning
firstpage: 17
lastpage: 32
page: 17-32
order: 17
cycles: false
author:
- given: Tobias
  family: Glasmachers
date: 2017-11-11
address: 
publisher: PMLR
container-title: Proceedings of the Ninth Asian Conference on Machine Learning
volume: '77'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 11
  - 11
pdf: http://proceedings.mlr.press/v77/glasmachers17a/glasmachers17a.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v77/glasmachers17a/glasmachers17a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
